{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "headline_score.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvgR19JRDLBaOdAm5c9AhY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flora0110/podcast_segment_headine/blob/main/headline_score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 比較token重複性"
      ],
      "metadata": {
        "id": "5XCimcbTA8UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn\n",
        "!pip install --user -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOenJtc_BvNX",
        "outputId": "a4a144af-2aca-454b-ccb4-bb37860a4a95"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting regex>=2021.8.3\n",
            "  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 35.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Installing collected packages: regex, nltk\n",
            "\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed nltk-3.7 regex-2022.4.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR9ACgzIBf6O",
        "outputId": "68c8b673-7aff-40b9-c397-4a1da61c053b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7dbPd0rB-rQW"
      },
      "outputs": [],
      "source": [
        "myheadline = [\"The Ins and Outs of Sugar\",\"The Brain - Body Contract Live Event Seattle on May 17th and Portland on May\",\"The Inside Tracker Podcast - Let It Greens\",\"The Effects of Sugar on the Nervous System\",\"Glucose Blood - What Is It?\",\"Insulin Response to Clamp Blood Glucose Levels\"]\n",
        "sample = [\"Sugar & Physiology\",\"The Brain-Body Contract\",\"Thesis, AG1 (Athletic Greens), InsideTracker\",\"Sugar & the Brain\",\"Appetite & Hormones: Ghrelin & Insulin\",\"Glucose & Brain Function\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 比較每個句子token的重複度(段數相同)"
      ],
      "metadata": {
        "id": "qayqEg1WDfiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length=6\n",
        "score = [\"0\"]*6\n",
        "for i in range(length):\n",
        "  #print(myheadline[i])\n",
        "  #print(sample[i])\n",
        "  myheadline_word = word_tokenize(myheadline[i])\n",
        "  sample_word = word_tokenize(sample[i])\n",
        "  same=0\n",
        "  for token in myheadline_word:\n",
        "    for token2 in sample_word:\n",
        "      if token==token2:\n",
        "        same+=1\n",
        "  #print(same)\n",
        "  #print((len(myheadline_word)+len(sample_word)-same))\n",
        "  score[i] = (same/(len(myheadline_word)+len(sample_word)-same))\n",
        "\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXDTIc_YC8En",
        "outputId": "a066cb46-9803-4d47-de90-fcbdcc88fe3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.125, 0.125, 0.0625, 0.2, 0.0, 0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for i in range(length):\n",
        "  sum+=score[i]\n",
        "\n",
        "print(\"score: \",(sum/length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghDPnPwkGT2n",
        "outputId": "d87a5743-2dfd-4f8d-bcb5-fdc875b1e692"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score:  0.10208333333333332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 去掉停用詞、標點符號"
      ],
      "metadata": {
        "id": "dilQFkeqHSsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer_common = RegexpTokenizer(r'\\w+')"
      ],
      "metadata": {
        "id": "YQXfuMNDJItp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-tlyVbZHNqh",
        "outputId": "708ef9f4-092a-4691-87eb-5ab675cf33fd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words.add(\"&\")\n",
        "stop_words.add(\"-\")"
      ],
      "metadata": {
        "id": "yVTF7gQrIntg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(length):\n",
        "  #print(myheadline[i])\n",
        "  #print(sample[i])\n",
        "  myheadline_word = tokenizer_common.tokenize(myheadline[i])\n",
        "  sample_word = tokenizer_common.tokenize(sample[i])\n",
        "  \n",
        "  same=0\n",
        "  myheadline_word_del = []\n",
        "  sample_word_del = []\n",
        "  for w in myheadline_word: \n",
        "    if w not in stop_words: \n",
        "      myheadline_word_del.append(w)\n",
        "  for w in sample_word: \n",
        "    if w not in stop_words: \n",
        "      sample_word_del.append(w)\n",
        "  print(myheadline_word_del)\n",
        "  print(sample_word_del)\n",
        "  for token in myheadline_word_del:\n",
        "    for token2 in sample_word_del:\n",
        "      if token==token2:\n",
        "        same+=1\n",
        "  #print(same)\n",
        "  #print((len(myheadline_word)+len(sample_word)-same))\n",
        "  score[i] = (same/(len(myheadline_word_del)+len(sample_word_del)-same))\n",
        "\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx98TTnDHdhn",
        "outputId": "990acee1-f721-4f9e-bdac-61534597271f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Ins', 'Outs', 'Sugar']\n",
            "['Sugar', 'Physiology']\n",
            "['The', 'Brain', 'Body', 'Contract', 'Live', 'Event', 'Seattle', 'May', '17th', 'Portland', 'May']\n",
            "['The', 'Brain', 'Body', 'Contract']\n",
            "['The', 'Inside', 'Tracker', 'Podcast', 'Let', 'It', 'Greens']\n",
            "['Thesis', 'AG1', 'Athletic', 'Greens', 'InsideTracker']\n",
            "['The', 'Effects', 'Sugar', 'Nervous', 'System']\n",
            "['Sugar', 'Brain']\n",
            "['Glucose', 'Blood', 'What', 'Is', 'It']\n",
            "['Appetite', 'Hormones', 'Ghrelin', 'Insulin']\n",
            "['Insulin', 'Response', 'Clamp', 'Blood', 'Glucose', 'Levels']\n",
            "['Glucose', 'Brain', 'Function']\n",
            "[0.2, 0.36363636363636365, 0.09090909090909091, 0.16666666666666666, 0.0, 0.125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for i in range(length):\n",
        "  sum+=score[i]\n",
        "\n",
        "print(\"score: \",(sum/length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZwaLv3RIKNo",
        "outputId": "007dc1b6-0d80-4037-950b-494b39eac9e9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score:  0.1577020202020202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 所有句子的重複度"
      ],
      "metadata": {
        "id": "lz6ufOa2GpRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myheadline_word2 = []\n",
        "sample_word2 = []\n",
        "\n",
        "for sent in myheadline:\n",
        "  temp = word_tokenize(sent)\n",
        "  myheadline_word2 += temp\n",
        "print(myheadline_word2)\n",
        "for sent in sample:\n",
        "  temp = word_tokenize(sent)\n",
        "  sample_word2 += temp\n",
        "print(sample_word2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn7lytqOCA6O",
        "outputId": "98d1e7dd-7569-4dc5-d834-d20a467500cb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Insulin', 'Response', 'to', 'Clamp', 'Blood', 'Glucose', 'Levels']\n",
            "['Glucose', '&', 'Brain', 'Function']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same2=0\n",
        "for token in myheadline_word2:\n",
        "  for token2 in sample_word2:\n",
        "    if token==token2:\n",
        "      same2+=1\n",
        "score2 = (same2/(len(myheadline_word2)+len(sample_word2)-same2))\n",
        "print(score2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfy0ZtF5G49_",
        "outputId": "2487a8d2-e11f-4f19-a54f-4948f42394a5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24615384615384617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 去掉停用詞、標點符號"
      ],
      "metadata": {
        "id": "Fbzw1zXlBJkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myheadline_word2 = []\n",
        "sample_word2 = []\n",
        "\n",
        "for sent in myheadline:\n",
        "  temp = tokenizer_common.tokenize(sent)\n",
        "  myheadline_word2 += temp\n",
        "print(myheadline_word2)\n",
        "for sent in sample:\n",
        "  temp = tokenizer_common.tokenize(sent)\n",
        "  sample_word2 += temp\n",
        "print(sample_word2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5uE-p4JKfB5",
        "outputId": "d85c0af9-08ed-4832-f0c7-4e4863b1bc66"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Ins', 'and', 'Outs', 'of', 'Sugar', 'The', 'Brain', 'Body', 'Contract', 'Live', 'Event', 'Seattle', 'on', 'May', '17th', 'and', 'Portland', 'on', 'May', 'The', 'Inside', 'Tracker', 'Podcast', 'Let', 'It', 'Greens', 'The', 'Effects', 'of', 'Sugar', 'on', 'the', 'Nervous', 'System', 'Glucose', 'Blood', 'What', 'Is', 'It', 'Insulin', 'Response', 'to', 'Clamp', 'Blood', 'Glucose', 'Levels']\n",
            "['Sugar', 'Physiology', 'The', 'Brain', 'Body', 'Contract', 'Thesis', 'AG1', 'Athletic', 'Greens', 'InsideTracker', 'Sugar', 'the', 'Brain', 'Appetite', 'Hormones', 'Ghrelin', 'Insulin', 'Glucose', 'Brain', 'Function']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same2=0\n",
        "for token in myheadline_word2:\n",
        "  for token2 in sample_word2:\n",
        "    if token==token2:\n",
        "      same2+=1\n",
        "score2 = (same2/(len(myheadline_word2)+len(sample_word2)-same2))\n",
        "print(score2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQWZUskKKpNJ",
        "outputId": "563dd5d2-a8fe-40de-ee23-6717bfb20c5c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mltk 餘弦相似度"
      ],
      "metadata": {
        "id": "AK5ZTNLRK2pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "def similarity_with_2_sents(vec1, vec2):\n",
        "  inner_product = 0\n",
        "  square_length_vec1 = 0\n",
        "  square_length_vec2 = 0\n",
        "  for tup1, tup2 in zip(vec1, vec2):\n",
        "      inner_product += tup1[1]*tup2[1]\n",
        "      square_length_vec1 += tup1[1]**2\n",
        "      square_length_vec2 += tup2[1]**2\n",
        "\n",
        "  return (inner_product/sqrt(square_length_vec1*square_length_vec2))"
      ],
      "metadata": {
        "id": "jbZfoYk2NDEJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "cosine_sim = [0]*length\n",
        "for i in range(length):\n",
        "  sents = [myheadline[i], sample[i]]\n",
        "  texts = [[word for word in word_tokenize(sent)] for sent in sents]\n",
        "  # print(texts)\n",
        "  all_list = []\n",
        "  for text in texts:\n",
        "      all_list += text\n",
        "  corpus = set(all_list)\n",
        "  print(corpus)\n",
        "  corpus_dict = dict(zip(corpus, range(len(corpus))))\n",
        "  print(corpus_dict)\n",
        "  # 建立句子的向量表示\n",
        "  def vector_rep(text, corpus_dict):\n",
        "      vec = []\n",
        "      for key in corpus_dict.keys():\n",
        "          if key in text:\n",
        "              vec.append((corpus_dict[key], text.count(key)))\n",
        "          else:\n",
        "              vec.append((corpus_dict[key], 0))\n",
        "\n",
        "      vec = sorted(vec, key= lambda x: x[0])\n",
        "\n",
        "      return vec\n",
        "\n",
        "  vec1 = vector_rep(texts[0], corpus_dict)\n",
        "  vec2 = vector_rep(texts[1], corpus_dict)\n",
        "  print(vec1)\n",
        "  print(vec2)\n",
        "  cosine_sim[i] = similarity_with_2_sents(vec1, vec2)\n",
        "  print('兩個句子的餘弦相似度為： %.4f。'%cosine_sim[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU8I9SELLPFx",
        "outputId": "dde7a85c-8034-4ef2-8a45-d35629d92942"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Outs', 'Ins', 'of', 'The', '&', 'Physiology', 'Sugar', 'and'}\n",
            "{'Outs': 0, 'Ins': 1, 'of': 2, 'The': 3, '&': 4, 'Physiology': 5, 'Sugar': 6, 'and': 7}\n",
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 0), (5, 0), (6, 1), (7, 1)]\n",
            "[(0, 0), (1, 0), (2, 0), (3, 0), (4, 1), (5, 1), (6, 1), (7, 0)]\n",
            "兩個句子的餘弦相似度為： 0.2357。\n",
            "{'May', 'on', 'Body', 'Event', 'Brain-Body', 'The', 'Live', 'Seattle', 'and', '-', 'Brain', 'Portland', 'Contract', '17th'}\n",
            "{'May': 0, 'on': 1, 'Body': 2, 'Event': 3, 'Brain-Body': 4, 'The': 5, 'Live': 6, 'Seattle': 7, 'and': 8, '-': 9, 'Brain': 10, 'Portland': 11, 'Contract': 12, '17th': 13}\n",
            "[(0, 2), (1, 2), (2, 1), (3, 1), (4, 0), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]\n",
            "[(0, 0), (1, 0), (2, 0), (3, 0), (4, 1), (5, 1), (6, 0), (7, 0), (8, 0), (9, 0), (10, 0), (11, 0), (12, 1), (13, 0)]\n",
            "兩個句子的餘弦相似度為： 0.2649。\n",
            "{'Athletic', 'Let', ',', 'Inside', 'Thesis', 'The', 'AG1', '(', 'It', '-', 'InsideTracker', 'Greens', 'Tracker', ')', 'Podcast'}\n",
            "{'Athletic': 0, 'Let': 1, ',': 2, 'Inside': 3, 'Thesis': 4, 'The': 5, 'AG1': 6, '(': 7, 'It': 8, '-': 9, 'InsideTracker': 10, 'Greens': 11, 'Tracker': 12, ')': 13, 'Podcast': 14}\n",
            "[(0, 0), (1, 1), (2, 0), (3, 1), (4, 0), (5, 1), (6, 0), (7, 0), (8, 1), (9, 1), (10, 0), (11, 1), (12, 1), (13, 0), (14, 1)]\n",
            "[(0, 1), (1, 0), (2, 2), (3, 0), (4, 1), (5, 0), (6, 1), (7, 1), (8, 0), (9, 0), (10, 1), (11, 1), (12, 0), (13, 1), (14, 0)]\n",
            "兩個句子的餘弦相似度為： 0.1066。\n",
            "{'on', 'the', 'of', 'The', '&', 'Sugar', 'Nervous', 'System', 'Brain', 'Effects'}\n",
            "{'on': 0, 'the': 1, 'of': 2, 'The': 3, '&': 4, 'Sugar': 5, 'Nervous': 6, 'System': 7, 'Brain': 8, 'Effects': 9}\n",
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 0), (5, 1), (6, 1), (7, 1), (8, 0), (9, 1)]\n",
            "[(0, 0), (1, 1), (2, 0), (3, 0), (4, 1), (5, 1), (6, 0), (7, 0), (8, 1), (9, 0)]\n",
            "兩個句子的餘弦相似度為： 0.3536。\n",
            "{'Is', 'Ghrelin', '?', 'What', '&', ':', 'It', '-', 'Blood', 'Glucose', 'Insulin', 'Appetite', 'Hormones'}\n",
            "{'Is': 0, 'Ghrelin': 1, '?': 2, 'What': 3, '&': 4, ':': 5, 'It': 6, '-': 7, 'Blood': 8, 'Glucose': 9, 'Insulin': 10, 'Appetite': 11, 'Hormones': 12}\n",
            "[(0, 1), (1, 0), (2, 1), (3, 1), (4, 0), (5, 0), (6, 1), (7, 1), (8, 1), (9, 1), (10, 0), (11, 0), (12, 0)]\n",
            "[(0, 0), (1, 1), (2, 0), (3, 0), (4, 2), (5, 1), (6, 0), (7, 0), (8, 0), (9, 0), (10, 1), (11, 1), (12, 1)]\n",
            "兩個句子的餘弦相似度為： 0.0000。\n",
            "{'Levels', 'Response', 'to', 'Function', 'Clamp', '&', 'Brain', 'Blood', 'Glucose', 'Insulin'}\n",
            "{'Levels': 0, 'Response': 1, 'to': 2, 'Function': 3, 'Clamp': 4, '&': 5, 'Brain': 6, 'Blood': 7, 'Glucose': 8, 'Insulin': 9}\n",
            "[(0, 1), (1, 1), (2, 1), (3, 0), (4, 1), (5, 0), (6, 0), (7, 1), (8, 1), (9, 1)]\n",
            "[(0, 0), (1, 0), (2, 0), (3, 1), (4, 0), (5, 1), (6, 1), (7, 0), (8, 1), (9, 0)]\n",
            "兩個句子的餘弦相似度為： 0.1890。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum3 = 0\n",
        "for i in range(length):\n",
        "  sum3+=cosine_sim[i]\n",
        "\n",
        "print(\"score: \",(sum3/length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brFqdQ29Ngtz",
        "outputId": "928905a5-3d8c-4310-ac08-a6c9284f506b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score:  0.1916241195140362\n"
          ]
        }
      ]
    }
  ]
}